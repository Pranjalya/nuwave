# NU-Wave &mdash; Official PyTorch Implementation

**NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling**
Junhyeok Lee, Seungu Han @ [MINDsLab Inc.](https://mindslab.ai), SNU

Paper: arXiv: https://arxiv.org/abs/2104.02321 (Submitted to INTERSPEECH 2021)<br>
Audio Samples: https://mindslab-ai.github.io/nuwave<br>

Code will be available soon! (Due to first author's mandatory military training, we are planning to open code *after June*)


## References

This implementation uses code from following repositories:
- [J.Ho's official DDPM implementation](https://github.com/hojonathanho/diffusion)
- [lucidrain's DDPM pytorch implementation](https://github.com/lucidrains/denoising-diffusion-pytorch)
- [ivanvok's WaveGrad pytorch implementation](https://github.com/ivanvovk/WaveGrad)
- [lmnt-com's DiffWave pytorch implementation](https://github.com/lmnt-com/diffwave)

This README and the webpage for the audio samples are inspired by:
- [Tips for Publishing Research Code](https://github.com/paperswithcode/releasing-research-code)
- [Audio samples webpage of DCA](https://google.github.io/tacotron/publications/location_relative_attention/)
- [Cotatron](https://github.com/mindslab-ai/cotatron/)
- [Audio samples wabpage of WaveGrad](https://wavegrad.github.io)

The audio samples on our [webpage](https://mindslab-ai.github.io/nuwave/) are partially derived from:
- [VCTK](https://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html): 46 hours of English speech from 108 speakers.
