# NU-Wave &mdash; Official PyTorch Implementation

**NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling**<br>
Junhyeok Lee, Seungu Han @ [MINDsLab Inc.](https://mindslab.ai), SNU

Paper(arXiv): https://arxiv.org/abs/2104.02321 (Accepted to INTERSPEECH 2021)<br>
Audio Samples: https://mindslab-ai.github.io/nuwave<br>

Update: Our paper is accepted to INTERSPEECH2021!!! We are planning to update paper and release code during June!

## References

This implementation uses code from following repositories:
- [J.Ho's official DDPM implementation](https://github.com/hojonathanho/diffusion)
- [lucidrain's DDPM pytorch implementation](https://github.com/lucidrains/denoising-diffusion-pytorch)
- [ivanvok's WaveGrad pytorch implementation](https://github.com/ivanvovk/WaveGrad)
- [lmnt-com's DiffWave pytorch implementation](https://github.com/lmnt-com/diffwave)

This README and the webpage for the audio samples are inspired by:
- [Tips for Publishing Research Code](https://github.com/paperswithcode/releasing-research-code)
- [Audio samples webpage of DCA](https://google.github.io/tacotron/publications/location_relative_attention/)
- [Cotatron](https://github.com/mindslab-ai/cotatron/)
- [Audio samples wabpage of WaveGrad](https://wavegrad.github.io)

The audio samples on our [webpage](https://mindslab-ai.github.io/nuwave/) are partially derived from:
- [VCTK](https://datashare.ed.ac.uk/handle/10283/3443): 46 hours of English speech from 108 speakers.
